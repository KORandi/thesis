[
  {
    "prompt": "The old house creaked in the wind, its windows [[cursor]]",
    "gptLatency": 554.871708,
    "llamaLatency": 502.4200420000002,
    "gptFirstTokenTime": 544.8538749999999,
    "llamaFirstTokenTime": 314.1945420000002,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 52.45166599999982
  },
  {
    "prompt": "She opened the mysterious package and found [[cursor]]",
    "gptLatency": 539.9718749999997,
    "llamaLatency": 663.7940830000007,
    "gptFirstTokenTime": 539.1407919999997,
    "llamaFirstTokenTime": 286.1429160000007,
    "gptTotalTokens": 6,
    "llamaTotalTokens": 8,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -123.82220800000096
  },
  {
    "prompt": "The storm clouds gathered overhead as the [[cursor]]",
    "gptLatency": 689.0267500000009,
    "llamaLatency": 521.121208999999,
    "gptFirstTokenTime": 576.076833000001,
    "llamaFirstTokenTime": 286.6634589999994,
    "gptTotalTokens": 8,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 167.9055410000019
  },
  {
    "prompt": "In the depths of the ancient forest, the [[cursor]]",
    "gptLatency": 445.25229200000103,
    "llamaLatency": 516.1282499999998,
    "gptFirstTokenTime": 444.48220800000126,
    "llamaFirstTokenTime": 281.39808300000004,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -70.87595799999872
  },
  {
    "prompt": "The scientist's latest experiment had resulted in [[cursor]]",
    "gptLatency": 722.7093329999989,
    "llamaLatency": 424.054500000002,
    "gptFirstTokenTime": 614.8296669999982,
    "llamaFirstTokenTime": 284.2821670000012,
    "gptTotalTokens": 7,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 298.65483299999687
  },
  {
    "prompt": "The quarterly report showed significant growth in [[cursor]]",
    "gptLatency": 496.0866249999999,
    "llamaLatency": 363.09829199999876,
    "gptFirstTokenTime": 463.43316699999923,
    "llamaFirstTokenTime": 271.05633300000045,
    "gptTotalTokens": 6,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 132.98833300000115
  },
  {
    "prompt": "During the stakeholder meeting, we discussed [[cursor]]",
    "gptLatency": 594.7096249999995,
    "llamaLatency": 505.29008299999987,
    "gptFirstTokenTime": 516.4955829999999,
    "llamaFirstTokenTime": 271.2099999999991,
    "gptTotalTokens": 7,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 89.41954199999964
  },
  {
    "prompt": "The new marketing strategy focuses on [[cursor]]",
    "gptLatency": 482.6744580000013,
    "llamaLatency": 503.4916250000024,
    "gptFirstTokenTime": 465.5446669999983,
    "llamaFirstTokenTime": 268.5877920000021,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -20.817167000001064
  },
  {
    "prompt": "Our team successfully implemented the [[cursor]]",
    "gptLatency": 566.9719170000026,
    "llamaLatency": 470.08925000000454,
    "gptFirstTokenTime": 560.5384580000027,
    "llamaFirstTokenTime": 283.3518750000003,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 96.88266699999804
  },
  {
    "prompt": "The client feedback indicated that [[cursor]]",
    "gptLatency": 484.7169580000045,
    "llamaLatency": 664.5129579999993,
    "gptFirstTokenTime": 477.7927500000005,
    "llamaFirstTokenTime": 286.4836660000001,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 8,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -179.79599999999482
  },
  {
    "prompt": "The system architecture consists of [[cursor]]",
    "gptLatency": 423.76045899999735,
    "llamaLatency": 410.8542910000033,
    "gptFirstTokenTime": 423.20979200000147,
    "llamaFirstTokenTime": 271.8064160000067,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 12.906167999994068
  },
  {
    "prompt": "To optimize the database performance, we [[cursor]]",
    "gptLatency": 548.0875419999938,
    "llamaLatency": 805.9722499999989,
    "gptFirstTokenTime": 515.898666999994,
    "llamaFirstTokenTime": 285.2194579999996,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 11,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -257.88470800000505
  },
  {
    "prompt": "The main function recursively calls [[cursor]]",
    "gptLatency": 702.4503750000003,
    "llamaLatency": 651.4852079999982,
    "gptFirstTokenTime": 701.3726670000033,
    "llamaFirstTokenTime": 275.96416699999827,
    "gptTotalTokens": 7,
    "llamaTotalTokens": 8,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 50.96516700000211
  },
  {
    "prompt": "The API endpoint returns [[cursor]]",
    "gptLatency": 544.3364999999976,
    "llamaLatency": 539.8435000000027,
    "gptFirstTokenTime": 543.8899170000004,
    "llamaFirstTokenTime": 401.16179099999863,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 4.492999999994936
  },
  {
    "prompt": "The deployment pipeline includes [[cursor]]",
    "gptLatency": 471.98441699999967,
    "llamaLatency": 502.2214160000003,
    "gptFirstTokenTime": 470.9010830000043,
    "llamaFirstTokenTime": 408.6241660000014,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -30.23699900000065
  },
  {
    "prompt": "The research findings suggest that [[cursor]]",
    "gptLatency": 604.1029169999965,
    "llamaLatency": 783.2412079999995,
    "gptFirstTokenTime": 567.978750000002,
    "llamaFirstTokenTime": 262.7578749999957,
    "gptTotalTokens": 6,
    "llamaTotalTokens": 11,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -179.13829100000294
  },
  {
    "prompt": "According to recent studies, the phenomenon [[cursor]]",
    "gptLatency": 489.4205840000068,
    "llamaLatency": 613.8504169999942,
    "gptFirstTokenTime": 478.5184169999993,
    "llamaFirstTokenTime": 284.9079999999958,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 7,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -124.42983299998741
  },
  {
    "prompt": "The data analysis reveals a strong correlation between [[cursor]]",
    "gptLatency": 458.3734589999949,
    "llamaLatency": 459.7476670000033,
    "gptFirstTokenTime": 458.138208999997,
    "llamaFirstTokenTime": 272.5050420000043,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -1.374208000008366
  },
  {
    "prompt": "The experimental results demonstrate [[cursor]]",
    "gptLatency": 440.1664579999924,
    "llamaLatency": 594.4209160000028,
    "gptFirstTokenTime": 439.39274999999907,
    "llamaFirstTokenTime": 406.5458750000107,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -154.25445800001035
  },
  {
    "prompt": "The literature review indicates [[cursor]]",
    "gptLatency": 622.0821250000008,
    "llamaLatency": 924.3543340000033,
    "gptFirstTokenTime": 586.4927080000052,
    "llamaFirstTokenTime": 405.893624999997,
    "gptTotalTokens": 9,
    "llamaTotalTokens": 11,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -302.2722090000025
  },
  {
    "prompt": "The mountain peak disappeared into [[cursor]]",
    "gptLatency": 541.5692920000001,
    "llamaLatency": 465.7653750000027,
    "gptFirstTokenTime": 540.6030420000025,
    "llamaFirstTokenTime": 280.30733399999735,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 75.80391699999745
  },
  {
    "prompt": "The child's laughter echoed through [[cursor]]",
    "gptLatency": 524.8919580000074,
    "llamaLatency": 422.10975000000326,
    "gptFirstTokenTime": 519.7227500000008,
    "llamaFirstTokenTime": 282.85800000000745,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 102.78220800000418
  },
  {
    "prompt": "The art exhibition featured [[cursor]]",
    "gptLatency": 555.4437500000058,
    "llamaLatency": 585.4083749999991,
    "gptFirstTokenTime": 454.1373339999991,
    "llamaFirstTokenTime": 398.40037499999744,
    "gptTotalTokens": 7,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -29.964624999993248
  },
  {
    "prompt": "The chef carefully prepared [[cursor]]",
    "gptLatency": 603.6587089999957,
    "llamaLatency": 581.5821250000008,
    "gptFirstTokenTime": 586.237374999997,
    "llamaFirstTokenTime": 393.61266699999396,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 22.07658399999491
  },
  {
    "prompt": "The garden bloomed with [[cursor]]",
    "gptLatency": 541.046709000002,
    "llamaLatency": 468.0824169999978,
    "gptFirstTokenTime": 536.2113339999923,
    "llamaFirstTokenTime": 280.8983329999901,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 72.9642920000042
  },
  {
    "prompt": "As the sun set behind the hills, she [[cursor]]",
    "gptLatency": 778.0218339999992,
    "llamaLatency": 663.64154099999,
    "gptFirstTokenTime": 692.193499999994,
    "llamaFirstTokenTime": 285.01558300000033,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 8,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 114.38029300000926
  },
  {
    "prompt": "The detective examined the evidence and [[cursor]]",
    "gptLatency": 508.6221249999944,
    "llamaLatency": 423.2044159999932,
    "gptFirstTokenTime": 468.8674159999937,
    "llamaFirstTokenTime": 284.3421249999956,
    "gptTotalTokens": 6,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 85.4177090000012
  },
  {
    "prompt": "After reviewing the documents, he realized [[cursor]]",
    "gptLatency": 522.8073330000043,
    "llamaLatency": 650.7142089999979,
    "gptFirstTokenTime": 510.16066700000374,
    "llamaFirstTokenTime": 273.99099999999453,
    "gptTotalTokens": 7,
    "llamaTotalTokens": 8,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -127.90687599999364
  },
  {
    "prompt": "The spacecraft's sensors detected [[cursor]]",
    "gptLatency": 528.837875000012,
    "llamaLatency": 647.7587919999933,
    "gptFirstTokenTime": 528.42366700001,
    "llamaFirstTokenTime": 271.4672500000015,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 8,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -118.92091699998127
  },
  {
    "prompt": "Walking through the abandoned building, they [[cursor]]",
    "gptLatency": 459.8290830000042,
    "llamaLatency": 456.924583,
    "gptFirstTokenTime": 442.16616700000304,
    "llamaFirstTokenTime": 269.63254099999904,
    "gptTotalTokens": 6,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 2.904500000004191
  },
  {
    "prompt": "I am writing to follow up on our discussion regarding [[cursor]]",
    "gptLatency": 481.0150419999991,
    "llamaLatency": 473.85674999999173,
    "gptFirstTokenTime": 454.70308300000033,
    "llamaFirstTokenTime": 286.99183299999277,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 7.15829200000735
  },
  {
    "prompt": "Thank you for your inquiry about [[cursor]]",
    "gptLatency": 652.841499999995,
    "llamaLatency": 461.22849999999744,
    "gptFirstTokenTime": 652.5056670000049,
    "llamaFirstTokenTime": 274.09791699999187,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 191.61299999999756
  },
  {
    "prompt": "I would like to schedule a meeting to discuss [[cursor]]",
    "gptLatency": 757.8002500000002,
    "llamaLatency": 468.600792000012,
    "gptFirstTokenTime": 750.6377499999944,
    "llamaFirstTokenTime": 281.695624999993,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 289.1994579999882
  },
  {
    "prompt": "Please find attached the documentation for [[cursor]]",
    "gptLatency": 439.96508300001733,
    "llamaLatency": 468.770709000004,
    "gptFirstTokenTime": 439.2185420000169,
    "llamaFirstTokenTime": 280.72087499999907,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -28.80562599998666
  },
  {
    "prompt": "In response to your request for [[cursor]]",
    "gptLatency": 784.7960000000021,
    "llamaLatency": 363.67125000001397,
    "gptFirstTokenTime": 521.326624999987,
    "llamaFirstTokenTime": 271.603208000015,
    "gptTotalTokens": 11,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 421.1247499999881
  },
  {
    "prompt": "The new feature implementation will require [[cursor]]",
    "gptLatency": 453.33924999999,
    "llamaLatency": 421.79716699998244,
    "gptFirstTokenTime": 452.67787499999395,
    "llamaFirstTokenTime": 281.4751249999972,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 31.54208300000755
  },
  {
    "prompt": "The testing phase revealed several [[cursor]]",
    "gptLatency": 456.4565419999999,
    "llamaLatency": 375.72641699999804,
    "gptFirstTokenTime": 456.19404199998826,
    "llamaFirstTokenTime": 283.74004199999035,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 80.73012500000186
  },
  {
    "prompt": "User feedback indicates that the interface [[cursor]]",
    "gptLatency": 481.87120799999684,
    "llamaLatency": 558.6784580000094,
    "gptFirstTokenTime": 481.26437499999884,
    "llamaFirstTokenTime": 275.9287079999922,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 6,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -76.80725000001257
  },
  {
    "prompt": "The security audit identified [[cursor]]",
    "gptLatency": 432.59779200001503,
    "llamaLatency": 465.73695900000166,
    "gptFirstTokenTime": 431.92525000000023,
    "llamaFirstTokenTime": 279.7322920000006,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -33.13916699998663
  },
  {
    "prompt": "The performance metrics show [[cursor]]",
    "gptLatency": 582.939000000013,
    "llamaLatency": 628.351708000002,
    "gptFirstTokenTime": 518.7257500000123,
    "llamaFirstTokenTime": 394.15891599998577,
    "gptTotalTokens": 8,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -45.412707999988925
  },
  {
    "prompt": "The cat quietly [[cursor]]",
    "gptLatency": 496.9664169999887,
    "llamaLatency": 668.5522919999785,
    "gptFirstTokenTime": 472.92566700000316,
    "llamaFirstTokenTime": 389.30091699998593,
    "gptTotalTokens": 6,
    "llamaTotalTokens": 6,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -171.58587499998976
  },
  {
    "prompt": "She quickly [[cursor]]",
    "gptLatency": 584.6599999999744,
    "llamaLatency": 574.302291,
    "gptFirstTokenTime": 559.8484590000007,
    "llamaFirstTokenTime": 385.06120799999917,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 10.35770899997442
  },
  {
    "prompt": "The software automatically [[cursor]]",
    "gptLatency": 566.0539159999753,
    "llamaLatency": 484.7396659999795,
    "gptFirstTokenTime": 565.7139999999781,
    "llamaFirstTokenTime": 390.9514579999959,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 81.31424999999581
  },
  {
    "prompt": "The machine learning model [[cursor]]",
    "gptLatency": 528.3905420000083,
    "llamaLatency": 536.3922500000044,
    "gptFirstTokenTime": 521.6972919999971,
    "llamaFirstTokenTime": 395.8061250000028,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -8.001707999996142
  },
  {
    "prompt": "The database query [[cursor]]",
    "gptLatency": 430.15783300000476,
    "llamaLatency": 521.2705840000126,
    "gptFirstTokenTime": 429.57199999998556,
    "llamaFirstTokenTime": 380.92741699999897,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -91.11275100000785
  },
  {
    "prompt": "Despite the challenges faced during development, the team [[cursor]]",
    "gptLatency": 575.213625000004,
    "llamaLatency": 709.4673749999783,
    "gptFirstTokenTime": 497.1735420000041,
    "llamaFirstTokenTime": 283.5087079999794,
    "gptTotalTokens": 7,
    "llamaTotalTokens": 9,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -134.2537499999744
  },
  {
    "prompt": "While analyzing the performance metrics, we discovered [[cursor]]",
    "gptLatency": 557.9196250000095,
    "llamaLatency": 645.2407919999969,
    "gptFirstTokenTime": 499.2051250000077,
    "llamaFirstTokenTime": 267.15266699998756,
    "gptTotalTokens": 7,
    "llamaTotalTokens": 8,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -87.32116699998733
  },
  {
    "prompt": "Although initial results were promising, further testing [[cursor]]",
    "gptLatency": 569.2290000000212,
    "llamaLatency": 613.2028749999881,
    "gptFirstTokenTime": 568.4716659999976,
    "llamaFirstTokenTime": 281.94195899998886,
    "gptTotalTokens": 6,
    "llamaTotalTokens": 7,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -43.97387499996694
  },
  {
    "prompt": "Considering the project requirements, we decided to [[cursor]]",
    "gptLatency": 543.1553339999809,
    "llamaLatency": 475.457000000024,
    "gptFirstTokenTime": 514.8539170000004,
    "llamaFirstTokenTime": 287.30883400002494,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 67.69833399995696
  },
  {
    "prompt": "After implementing the new algorithm, the system [[cursor]]",
    "gptLatency": 585.3017920000129,
    "llamaLatency": 469.37770799998543,
    "gptFirstTokenTime": 538.1158750000177,
    "llamaFirstTokenTime": 282.02691600000253,
    "gptTotalTokens": 7,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 115.9240840000275
  },
  {
    "prompt": "\"I never expected to find,\" she whispered [[cursor]]",
    "gptLatency": 586.885500000004,
    "llamaLatency": 511.82620800001314,
    "gptFirstTokenTime": 497.2595830000064,
    "llamaFirstTokenTime": 277.76183299999684,
    "gptTotalTokens": 9,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 75.05929199999082
  },
  {
    "prompt": "\"The results are fascinating,\" the researcher noted [[cursor]]",
    "gptLatency": 458.6494170000078,
    "llamaLatency": 418.7162499999977,
    "gptFirstTokenTime": 457.9114589999954,
    "llamaFirstTokenTime": 278.5061670000141,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 39.933167000010144
  },
  {
    "prompt": "\"According to our analysis,\" the expert explained [[cursor]]",
    "gptLatency": 773.00450000001,
    "llamaLatency": 612.5903749999998,
    "gptFirstTokenTime": 646.1048339999979,
    "llamaFirstTokenTime": 284.60570800001733,
    "gptTotalTokens": 11,
    "llamaTotalTokens": 7,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 160.41412500001024
  },
  {
    "prompt": "\"We need to consider,\" the manager suggested [[cursor]]",
    "gptLatency": 558.2056659999944,
    "llamaLatency": 469.58291699999245,
    "gptFirstTokenTime": 443.6683749999793,
    "llamaFirstTokenTime": 282.99895899998955,
    "gptTotalTokens": 12,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 88.62274900000193
  },
  {
    "prompt": "\"The solution involves,\" the engineer stated [[cursor]]",
    "gptLatency": 706.4353330000013,
    "llamaLatency": 602.843583000009,
    "gptFirstTokenTime": 521.675332999992,
    "llamaFirstTokenTime": 274.6524999999965,
    "gptTotalTokens": 11,
    "llamaTotalTokens": 7,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 103.59174999999232
  },
  {
    "prompt": "The program executes the following steps: [[cursor]]",
    "gptLatency": 551.4565839999996,
    "llamaLatency": 509.1309590000019,
    "gptFirstTokenTime": 550.4871250000142,
    "llamaFirstTokenTime": 275.231958999997,
    "gptTotalTokens": 7,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 42.32562499999767
  },
  {
    "prompt": "The automated process begins by [[cursor]]",
    "gptLatency": 658.3678329999966,
    "llamaLatency": 467.4820419999887,
    "gptFirstTokenTime": 645.2421249999898,
    "llamaFirstTokenTime": 280.69866699998965,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 190.88579100000788
  },
  {
    "prompt": "The user interface responds by [[cursor]]",
    "gptLatency": 447.37341699999524,
    "llamaLatency": 515.5135000000009,
    "gptFirstTokenTime": 445.68116700000246,
    "llamaFirstTokenTime": 281.0535830000008,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -68.14008300000569
  },
  {
    "prompt": "The system automatically [[cursor]]",
    "gptLatency": 432.3167919999978,
    "llamaLatency": 528.0591669999994,
    "gptFirstTokenTime": 431.60899999999674,
    "llamaFirstTokenTime": 387.2253750000091,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -95.74237500000163
  },
  {
    "prompt": "The algorithm processes the data by [[cursor]]",
    "gptLatency": 531.4772919999959,
    "llamaLatency": 422.73541600001045,
    "gptFirstTokenTime": 500.65291699999943,
    "llamaFirstTokenTime": 282.9680830000143,
    "gptTotalTokens": 7,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 108.7418759999855
  },
  {
    "prompt": "The new version must be able to [[cursor]]",
    "gptLatency": 594.972207999992,
    "llamaLatency": 505.2279580000031,
    "gptFirstTokenTime": 594.4186249999912,
    "llamaFirstTokenTime": 270.6219170000113,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 89.74424999998882
  },
  {
    "prompt": "The application should handle [[cursor]]",
    "gptLatency": 577.0962909999944,
    "llamaLatency": 592.1905000000261,
    "gptFirstTokenTime": 565.8279160000093,
    "llamaFirstTokenTime": 407.01625000001513,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -15.094209000031697
  },
  {
    "prompt": "Users need to be able to [[cursor]]",
    "gptLatency": 628.046417000005,
    "llamaLatency": 514.1128749999916,
    "gptFirstTokenTime": 600.8734579999873,
    "llamaFirstTokenTime": 280.72254200000316,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 113.9335420000134
  },
  {
    "prompt": "The system must automatically [[cursor]]",
    "gptLatency": 534.1555830000143,
    "llamaLatency": 375.5047499999928,
    "gptFirstTokenTime": 533.5002920000115,
    "llamaFirstTokenTime": 283.465750000003,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 158.65083300002152
  },
  {
    "prompt": "The interface should provide [[cursor]]",
    "gptLatency": 465.76833400002215,
    "llamaLatency": 451.8662910000421,
    "gptFirstTokenTime": 460.76558399997884,
    "llamaFirstTokenTime": 405.14054100000067,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 1,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 13.90204299998004
  },
  {
    "prompt": "If the connection fails, the system will [[cursor]]",
    "gptLatency": 576.9549579999875,
    "llamaLatency": 377.0086669999873,
    "gptFirstTokenTime": 571.9208750000107,
    "llamaFirstTokenTime": 284.795792000019,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 199.9462910000002
  },
  {
    "prompt": "When an error occurs, the application should [[cursor]]",
    "gptLatency": 551.1478750000242,
    "llamaLatency": 468.4685419999878,
    "gptFirstTokenTime": 544.1713750000345,
    "llamaFirstTokenTime": 281.9484999999986,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 82.67933300003642
  },
  {
    "prompt": "In case of data corruption, the backup [[cursor]]",
    "gptLatency": 536.542208000028,
    "llamaLatency": 702.9305419999873,
    "gptFirstTokenTime": 518.0890409999993,
    "llamaFirstTokenTime": 280.1156249999767,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 9,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -166.3883339999593
  },
  {
    "prompt": "The error handling routine checks for [[cursor]]",
    "gptLatency": 638.8051250000135,
    "llamaLatency": 372.4402499999851,
    "gptFirstTokenTime": 606.52224999998,
    "llamaFirstTokenTime": 280.3301249999786,
    "gptTotalTokens": 6,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 266.3648750000284
  },
  {
    "prompt": "If validation fails, the form will [[cursor]]",
    "gptLatency": 671.8761249999516,
    "llamaLatency": 373.3101669999887,
    "gptFirstTokenTime": 638.9989169999608,
    "llamaFirstTokenTime": 281.59008399996674,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 298.56595799996285
  },
  {
    "prompt": "The autocomplete functionality allows users to [[cursor]]",
    "gptLatency": 547.5175000000163,
    "llamaLatency": 469.37570800003596,
    "gptFirstTokenTime": 536.0692910000216,
    "llamaFirstTokenTime": 282.6148750000284,
    "gptTotalTokens": 6,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 78.14179199998034
  },
  {
    "prompt": "The new dashboard displays [[cursor]]",
    "gptLatency": 557.5329170000041,
    "llamaLatency": 776.0793340000091,
    "gptFirstTokenTime": 550.546417000005,
    "llamaFirstTokenTime": 399.9407089999877,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 8,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -218.54641700000502
  },
  {
    "prompt": "The search feature includes [[cursor]]",
    "gptLatency": 570.6074160000426,
    "llamaLatency": 593.5617079999647,
    "gptFirstTokenTime": 570.1942080000299,
    "llamaFirstTokenTime": 408.2389999999432,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -22.954291999922134
  },
  {
    "prompt": "The notification system alerts users when [[cursor]]",
    "gptLatency": 497.0330829999875,
    "llamaLatency": 513.6468340000138,
    "gptFirstTokenTime": 496.8876249999739,
    "llamaFirstTokenTime": 280.12320899998304,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -16.61375100002624
  },
  {
    "prompt": "The export function generates [[cursor]]",
    "gptLatency": 472.6844170000404,
    "llamaLatency": 451.3014579999726,
    "gptFirstTokenTime": 472.3627090000082,
    "llamaFirstTokenTime": 404.79745799995726,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 1,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 21.382959000067785
  },
  {
    "prompt": "The installation process requires [[cursor]]",
    "gptLatency": 590.3612500000163,
    "llamaLatency": 591.1401659999974,
    "gptFirstTokenTime": 553.4415840000147,
    "llamaFirstTokenTime": 406.6668329999666,
    "gptTotalTokens": 6,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -0.778915999981109
  },
  {
    "prompt": "The configuration file contains [[cursor]]",
    "gptLatency": 540.5180840000394,
    "llamaLatency": 689.781083000009,
    "gptFirstTokenTime": 539.7350000000442,
    "llamaFirstTokenTime": 408.8620419999934,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 6,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -149.26299899996957
  },
  {
    "prompt": "The API documentation describes [[cursor]]",
    "gptLatency": 486.31566700001713,
    "llamaLatency": 971.4239170000073,
    "gptFirstTokenTime": 447.7742919999873,
    "llamaFirstTokenTime": 408.63904199999524,
    "gptTotalTokens": 7,
    "llamaTotalTokens": 12,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -485.1082499999902
  },
  {
    "prompt": "The user guide explains how to [[cursor]]",
    "gptLatency": 528.5137090000208,
    "llamaLatency": 462.2782920000027,
    "gptFirstTokenTime": 495.59116700000595,
    "llamaFirstTokenTime": 279.101250000007,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": 66.23541700001806
  },
  {
    "prompt": "The troubleshooting section covers [[cursor]]",
    "gptLatency": 546.3836659999797,
    "llamaLatency": 780.1456669999752,
    "gptFirstTokenTime": 545.7669579999638,
    "llamaFirstTokenTime": 408.67008399998304,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 8,
    "timestamp": "2024-12-01T23:06:34.320Z",
    "difference": -233.7620009999955
  }
]