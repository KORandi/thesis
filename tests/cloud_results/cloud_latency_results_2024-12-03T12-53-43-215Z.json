[
  {
    "prompt": "The old house creaked in the wind, its windows [[cursor]]",
    "gptLatency": 1402.170541,
    "llamaLatency": 255.86920800000007,
    "gptFirstTokenTime": 1401.5425,
    "llamaFirstTokenTime": 232.61391700000013,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 1146.3013329999999
  },
  {
    "prompt": "She opened the mysterious package and found [[cursor]]",
    "gptLatency": 546.4659160000001,
    "llamaLatency": 280.0303750000003,
    "gptFirstTokenTime": 523.9943330000006,
    "llamaFirstTokenTime": 232.4476249999998,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 6,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 266.43554099999983
  },
  {
    "prompt": "The storm clouds gathered overhead as the [[cursor]]",
    "gptLatency": 608.764083,
    "llamaLatency": 267.9451250000002,
    "gptFirstTokenTime": 529.369666999999,
    "llamaFirstTokenTime": 226.7024590000001,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 340.81895799999984
  },
  {
    "prompt": "In the depths of the ancient forest, the [[cursor]]",
    "gptLatency": 711.0194580000007,
    "llamaLatency": 270.94924999999967,
    "gptFirstTokenTime": 697.2719580000012,
    "llamaFirstTokenTime": 230.14149999999972,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 440.070208000001
  },
  {
    "prompt": "The scientist's latest experiment had resulted in [[cursor]]",
    "gptLatency": 587.1158329999998,
    "llamaLatency": 254.35404199999903,
    "gptFirstTokenTime": 530.6165829999991,
    "llamaFirstTokenTime": 226.679791999999,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 332.7617910000008
  },
  {
    "prompt": "The quarterly report showed significant growth in [[cursor]]",
    "gptLatency": 561.6777919999986,
    "llamaLatency": 251.17433399999936,
    "gptFirstTokenTime": 561.325499999999,
    "llamaFirstTokenTime": 235.82066699999996,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 310.5034579999992
  },
  {
    "prompt": "During the stakeholder meeting, we discussed [[cursor]]",
    "gptLatency": 636.4745419999999,
    "llamaLatency": 271.68783299999996,
    "gptFirstTokenTime": 636.0745420000021,
    "llamaFirstTokenTime": 228.86425000000236,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 364.786709
  },
  {
    "prompt": "The new marketing strategy focuses on [[cursor]]",
    "gptLatency": 618.4751660000002,
    "llamaLatency": 259.2932089999995,
    "gptFirstTokenTime": 618.0978749999995,
    "llamaFirstTokenTime": 235.0109169999996,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 359.1819570000007
  },
  {
    "prompt": "Our team successfully implemented the [[cursor]]",
    "gptLatency": 623.8542500000003,
    "llamaLatency": 431.2105410000004,
    "gptFirstTokenTime": 623.453375000001,
    "llamaFirstTokenTime": 430.7796249999956,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 1,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 192.64370899999994
  },
  {
    "prompt": "The client feedback indicated that [[cursor]]",
    "gptLatency": 506.13220799999544,
    "llamaLatency": 263.85654099999374,
    "gptFirstTokenTime": 500.3913329999996,
    "llamaFirstTokenTime": 232.120124999994,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 242.2756670000017
  },
  {
    "prompt": "The system architecture consists of [[cursor]]",
    "gptLatency": 536.6745410000003,
    "llamaLatency": 263.9080419999955,
    "gptFirstTokenTime": 530.6369160000031,
    "llamaFirstTokenTime": 238.86879200000112,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 272.76649900000484
  },
  {
    "prompt": "To optimize the database performance, we [[cursor]]",
    "gptLatency": 562.3010409999988,
    "llamaLatency": 279.0204999999987,
    "gptFirstTokenTime": 532.663708,
    "llamaFirstTokenTime": 231.1569159999999,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 6,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 283.2805410000001
  },
  {
    "prompt": "The main function recursively calls [[cursor]]",
    "gptLatency": 574.804250000001,
    "llamaLatency": 259.29899999999907,
    "gptFirstTokenTime": 498.06837500000256,
    "llamaFirstTokenTime": 235.46595800000068,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 315.505250000002
  },
  {
    "prompt": "The API endpoint returns [[cursor]]",
    "gptLatency": 727.8417919999993,
    "llamaLatency": 255.15479100000084,
    "gptFirstTokenTime": 727.5214169999963,
    "llamaFirstTokenTime": 233.36579099999653,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 472.6870009999984
  },
  {
    "prompt": "The deployment pipeline includes [[cursor]]",
    "gptLatency": 603.4624160000021,
    "llamaLatency": 248.80649999999878,
    "gptFirstTokenTime": 567.088208000001,
    "llamaFirstTokenTime": 230.99237500000163,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 354.65591600000334
  },
  {
    "prompt": "The research findings suggest that [[cursor]]",
    "gptLatency": 588.3359160000036,
    "llamaLatency": 325.45537499999773,
    "gptFirstTokenTime": 548.4340830000001,
    "llamaFirstTokenTime": 233.2554999999993,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 11,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 262.8805410000059
  },
  {
    "prompt": "According to recent studies, the phenomenon [[cursor]]",
    "gptLatency": 528.3192909999998,
    "llamaLatency": 313.3736250000002,
    "gptFirstTokenTime": 522.577833000003,
    "llamaFirstTokenTime": 231.86266699999396,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 10,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 214.94566599999962
  },
  {
    "prompt": "The data analysis reveals a strong correlation between [[cursor]]",
    "gptLatency": 526.2646249999962,
    "llamaLatency": 280.1889999999985,
    "gptFirstTokenTime": 520.5024579999881,
    "llamaFirstTokenTime": 239.23908300000767,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 246.07562499999767
  },
  {
    "prompt": "The experimental results demonstrate [[cursor]]",
    "gptLatency": 573.8717920000054,
    "llamaLatency": 324.64483399999153,
    "gptFirstTokenTime": 525.3273330000084,
    "llamaFirstTokenTime": 242.76266699998814,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 10,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 249.22695800001384
  },
  {
    "prompt": "The literature review indicates [[cursor]]",
    "gptLatency": 736.5141250000015,
    "llamaLatency": 276.25191600000835,
    "gptFirstTokenTime": 680.5063750000118,
    "llamaFirstTokenTime": 234.47158300000592,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 460.26220899999316
  },
  {
    "prompt": "The mountain peak disappeared into [[cursor]]",
    "gptLatency": 689.6174159999937,
    "llamaLatency": 248.98274999999558,
    "gptFirstTokenTime": 689.2332079999906,
    "llamaFirstTokenTime": 234.23387500000536,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 440.6346659999981
  },
  {
    "prompt": "The child's laughter echoed through [[cursor]]",
    "gptLatency": 560.132334000009,
    "llamaLatency": 254.19216599999345,
    "gptFirstTokenTime": 559.7221669999999,
    "llamaFirstTokenTime": 228.02162499999395,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 305.94016800001555
  },
  {
    "prompt": "The art exhibition featured [[cursor]]",
    "gptLatency": 671.7225000000035,
    "llamaLatency": 259.0902500000084,
    "gptFirstTokenTime": 671.3361659999937,
    "llamaFirstTokenTime": 226.2455830000108,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 412.6322499999951
  },
  {
    "prompt": "The chef carefully prepared [[cursor]]",
    "gptLatency": 700.1213329999882,
    "llamaLatency": 267.7508749999979,
    "gptFirstTokenTime": 636.1882079999923,
    "llamaFirstTokenTime": 226.6325829999987,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 432.3704579999903
  },
  {
    "prompt": "The garden bloomed with [[cursor]]",
    "gptLatency": 636.1660839999968,
    "llamaLatency": 274.02654199999233,
    "gptFirstTokenTime": 635.8219589999935,
    "llamaFirstTokenTime": 238.98016700000153,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 362.13954200000444
  },
  {
    "prompt": "As the sun set behind the hills, she [[cursor]]",
    "gptLatency": 538.1678749999992,
    "llamaLatency": 287.5910830000066,
    "gptFirstTokenTime": 514.020749999996,
    "llamaFirstTokenTime": 221.0903330000001,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 8,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 250.57679199999257
  },
  {
    "prompt": "The detective examined the evidence and [[cursor]]",
    "gptLatency": 600.1764160000021,
    "llamaLatency": 374.15508399999817,
    "gptFirstTokenTime": 571.1490829999966,
    "llamaFirstTokenTime": 338.0583340000012,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 226.0213320000039
  },
  {
    "prompt": "After reviewing the documents, he realized [[cursor]]",
    "gptLatency": 587.7712500000052,
    "llamaLatency": 295.6219999999885,
    "gptFirstTokenTime": 526.0997910000006,
    "llamaFirstTokenTime": 228.77637499998673,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 8,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 292.14925000001676
  },
  {
    "prompt": "The spacecraft's sensors detected [[cursor]]",
    "gptLatency": 590.4796670000069,
    "llamaLatency": 266.15587499999674,
    "gptFirstTokenTime": 590.1205830000108,
    "llamaFirstTokenTime": 232.19899999999325,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 324.32379200001014
  },
  {
    "prompt": "Walking through the abandoned building, they [[cursor]]",
    "gptLatency": 676.9998749999941,
    "llamaLatency": 272.77358300000196,
    "gptFirstTokenTime": 598.9516250000015,
    "llamaFirstTokenTime": 231.71529100000043,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 404.2262919999921
  },
  {
    "prompt": "I am writing to follow up on our discussion regarding [[cursor]]",
    "gptLatency": 530.5908339999878,
    "llamaLatency": 249.97270800000115,
    "gptFirstTokenTime": 506.2009589999943,
    "llamaFirstTokenTime": 225.91062500000407,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 280.61812599998666
  },
  {
    "prompt": "Thank you for your inquiry about [[cursor]]",
    "gptLatency": 503.0225000000064,
    "llamaLatency": 286.4992499999935,
    "gptFirstTokenTime": 502.58400000000256,
    "llamaFirstTokenTime": 251.95500000000175,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 216.52325000001292
  },
  {
    "prompt": "I would like to schedule a meeting to discuss [[cursor]]",
    "gptLatency": 658.6959170000046,
    "llamaLatency": 257.06124999999884,
    "gptFirstTokenTime": 658.341499999995,
    "llamaFirstTokenTime": 230.74591699999291,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 401.6346670000057
  },
  {
    "prompt": "Please find attached the documentation for [[cursor]]",
    "gptLatency": 524.2609579999989,
    "llamaLatency": 268.7428749999963,
    "gptFirstTokenTime": 523.9790420000063,
    "llamaFirstTokenTime": 229.67412499999045,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 255.51808300000266
  },
  {
    "prompt": "In response to your request for [[cursor]]",
    "gptLatency": 615.2789170000178,
    "llamaLatency": 261.71749999999884,
    "gptFirstTokenTime": 496.4438749999972,
    "llamaFirstTokenTime": 235.47320900001796,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 353.561417000019
  },
  {
    "prompt": "The new feature implementation will require [[cursor]]",
    "gptLatency": 541.4574579999899,
    "llamaLatency": 270.56066600000486,
    "gptFirstTokenTime": 519.9614169999841,
    "llamaFirstTokenTime": 226.6410409999953,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 270.896791999985
  },
  {
    "prompt": "The testing phase revealed several [[cursor]]",
    "gptLatency": 731.3904170000169,
    "llamaLatency": 231.19491700001527,
    "gptFirstTokenTime": 730.9733340000093,
    "llamaFirstTokenTime": 224.75845900000422,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 1,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 500.19550000000163
  },
  {
    "prompt": "User feedback indicates that the interface [[cursor]]",
    "gptLatency": 533.1729999999807,
    "llamaLatency": 262.7017920000071,
    "gptFirstTokenTime": 532.8328340000007,
    "llamaFirstTokenTime": 229.90216699999291,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 270.47120799997356
  },
  {
    "prompt": "The security audit identified [[cursor]]",
    "gptLatency": 512.4149579999794,
    "llamaLatency": 256.0689579999889,
    "gptFirstTokenTime": 512.0119579999882,
    "llamaFirstTokenTime": 222.20799999998417,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 256.34599999999045
  },
  {
    "prompt": "The performance metrics show [[cursor]]",
    "gptLatency": 597.4089160000149,
    "llamaLatency": 255.59108299997752,
    "gptFirstTokenTime": 526.9794580000162,
    "llamaFirstTokenTime": 231.91554099999485,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 341.81783300003735
  },
  {
    "prompt": "The cat quietly [[cursor]]",
    "gptLatency": 673.486459000007,
    "llamaLatency": 243.48837499998626,
    "gptFirstTokenTime": 663.2014590000035,
    "llamaFirstTokenTime": 225.67404099999112,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 429.99808400002075
  },
  {
    "prompt": "She quickly [[cursor]]",
    "gptLatency": 503.16908299998613,
    "llamaLatency": 272.112999999983,
    "gptFirstTokenTime": 492.6692079999775,
    "llamaFirstTokenTime": 231.2666249999893,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 231.05608300000313
  },
  {
    "prompt": "The software automatically [[cursor]]",
    "gptLatency": 525.3842920000025,
    "llamaLatency": 230.34916699997848,
    "gptFirstTokenTime": 525.0163339999854,
    "llamaFirstTokenTime": 222.89195799999288,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 1,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 295.035125000024
  },
  {
    "prompt": "The machine learning model [[cursor]]",
    "gptLatency": 537.9835839999723,
    "llamaLatency": 293.5901249999879,
    "gptFirstTokenTime": 527.4163339999795,
    "llamaFirstTokenTime": 226.9855830000015,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 8,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 244.39345899998443
  },
  {
    "prompt": "The database query [[cursor]]",
    "gptLatency": 657.0113340000098,
    "llamaLatency": 266.01158299998497,
    "gptFirstTokenTime": 656.5894590000098,
    "llamaFirstTokenTime": 231.1485409999732,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 390.99975100002484
  },
  {
    "prompt": "Despite the challenges faced during development, the team [[cursor]]",
    "gptLatency": 739.9341669999994,
    "llamaLatency": 287.6368749999965,
    "gptFirstTokenTime": 692.3957080000255,
    "llamaFirstTokenTime": 237.6957499999844,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 6,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 452.2972920000029
  },
  {
    "prompt": "While analyzing the performance metrics, we discovered [[cursor]]",
    "gptLatency": 757.6478749999951,
    "llamaLatency": 270.4237079999875,
    "gptFirstTokenTime": 757.2599580000096,
    "llamaFirstTokenTime": 236.34512499999255,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 487.2241670000076
  },
  {
    "prompt": "Although initial results were promising, further testing [[cursor]]",
    "gptLatency": 700.11387500001,
    "llamaLatency": 293.3605830000015,
    "gptFirstTokenTime": 657.5048750000133,
    "llamaFirstTokenTime": 234.77066700000432,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 7,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 406.7532920000085
  },
  {
    "prompt": "Considering the project requirements, we decided to [[cursor]]",
    "gptLatency": 656.5675420000043,
    "llamaLatency": 270.23795899999095,
    "gptFirstTokenTime": 635.1639999999898,
    "llamaFirstTokenTime": 236.94441699999152,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 386.3295830000134
  },
  {
    "prompt": "After implementing the new algorithm, the system [[cursor]]",
    "gptLatency": 572.9793749999953,
    "llamaLatency": 273.19383299999754,
    "gptFirstTokenTime": 567.7577089999977,
    "llamaFirstTokenTime": 234.03404200001387,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 299.7855419999978
  },
  {
    "prompt": "\"I never expected to find,\" she whispered [[cursor]]",
    "gptLatency": 603.3160829999833,
    "llamaLatency": 265.4329580000194,
    "gptFirstTokenTime": 593.7072499999776,
    "llamaFirstTokenTime": 230.80791699999827,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 337.8831249999639
  },
  {
    "prompt": "\"The results are fascinating,\" the researcher noted [[cursor]]",
    "gptLatency": 629.5139999999956,
    "llamaLatency": 251.206749999983,
    "gptFirstTokenTime": 629.1723749999946,
    "llamaFirstTokenTime": 235.76829099998577,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 378.3072500000126
  },
  {
    "prompt": "\"According to our analysis,\" the expert explained [[cursor]]",
    "gptLatency": 732.6555000000226,
    "llamaLatency": 248.1469170000055,
    "gptFirstTokenTime": 558.9499170000199,
    "llamaFirstTokenTime": 230.50333300000057,
    "gptTotalTokens": 6,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 484.5085830000171
  },
  {
    "prompt": "\"We need to consider,\" the manager suggested [[cursor]]",
    "gptLatency": 638.389124999987,
    "llamaLatency": 267.4121660000237,
    "gptFirstTokenTime": 550.3598340000026,
    "llamaFirstTokenTime": 234.5302500000107,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 370.97695899996324
  },
  {
    "prompt": "\"The solution involves,\" the engineer stated [[cursor]]",
    "gptLatency": 663.7964999999967,
    "llamaLatency": 262.534416999988,
    "gptFirstTokenTime": 517.9992499999935,
    "llamaFirstTokenTime": 227.67399999999907,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 401.2620830000087
  },
  {
    "prompt": "The program executes the following steps: [[cursor]]",
    "gptLatency": 562.5098750000179,
    "llamaLatency": 257.96100000001024,
    "gptFirstTokenTime": 532.9764590000268,
    "llamaFirstTokenTime": 225.10175000000163,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 304.5488750000077
  },
  {
    "prompt": "The automated process begins by [[cursor]]",
    "gptLatency": 549.5310419999878,
    "llamaLatency": 246.2025830000057,
    "gptFirstTokenTime": 549.1739579999994,
    "llamaFirstTokenTime": 230.39175000000978,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 303.3284589999821
  },
  {
    "prompt": "The user interface responds by [[cursor]]",
    "gptLatency": 687.6074999999837,
    "llamaLatency": 269.2848750000121,
    "gptFirstTokenTime": 681.2276249999995,
    "llamaFirstTokenTime": 230.19066699998803,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 418.3226249999716
  },
  {
    "prompt": "The system automatically [[cursor]]",
    "gptLatency": 450.3316249999916,
    "llamaLatency": 244.71991700000945,
    "gptFirstTokenTime": 449.9215839999961,
    "llamaFirstTokenTime": 236.93666700000176,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 1,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 205.61170799998217
  },
  {
    "prompt": "The algorithm processes the data by [[cursor]]",
    "gptLatency": 691.7058749999851,
    "llamaLatency": 258.8618750000023,
    "gptFirstTokenTime": 574.6289169999945,
    "llamaFirstTokenTime": 232.38054199999897,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 432.84399999998277
  },
  {
    "prompt": "The new version must be able to [[cursor]]",
    "gptLatency": 740.6974580000096,
    "llamaLatency": 269.5656660000095,
    "gptFirstTokenTime": 740.4814170000027,
    "llamaFirstTokenTime": 228.52995799999917,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 471.13179200000013
  },
  {
    "prompt": "The application should handle [[cursor]]",
    "gptLatency": 596.3063329999859,
    "llamaLatency": 286.1513339999947,
    "gptFirstTokenTime": 595.8800000000047,
    "llamaFirstTokenTime": 234.49008399999002,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 6,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 310.1549989999912
  },
  {
    "prompt": "Users need to be able to [[cursor]]",
    "gptLatency": 515.5502500000002,
    "llamaLatency": 244.93700000000536,
    "gptFirstTokenTime": 495.1824170000036,
    "llamaFirstTokenTime": 227.38591599999927,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 270.6132499999949
  },
  {
    "prompt": "The system must automatically [[cursor]]",
    "gptLatency": 506.54012499999953,
    "llamaLatency": 251.1071670000092,
    "gptFirstTokenTime": 506.08116600001813,
    "llamaFirstTokenTime": 229.14004199998453,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 255.43295799999032
  },
  {
    "prompt": "The interface should provide [[cursor]]",
    "gptLatency": 520.2553330000082,
    "llamaLatency": 232.10087500000373,
    "gptFirstTokenTime": 512.1632080000127,
    "llamaFirstTokenTime": 224.93691699998453,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 1,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 288.1544580000045
  },
  {
    "prompt": "If the connection fails, the system will [[cursor]]",
    "gptLatency": 682.5175410000084,
    "llamaLatency": 252.18124999999418,
    "gptFirstTokenTime": 675.4885829999985,
    "llamaFirstTokenTime": 236.82858299999498,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 430.33629100001417
  },
  {
    "prompt": "When an error occurs, the application should [[cursor]]",
    "gptLatency": 498.6809169999906,
    "llamaLatency": 276.11583399999654,
    "gptFirstTokenTime": 493.0955419999955,
    "llamaFirstTokenTime": 234.99370899997302,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 222.56508299999405
  },
  {
    "prompt": "In case of data corruption, the backup [[cursor]]",
    "gptLatency": 543.9961670000048,
    "llamaLatency": 290.46199999999953,
    "gptFirstTokenTime": 519.7018329999992,
    "llamaFirstTokenTime": 225.26262499997392,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 8,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 253.53416700000525
  },
  {
    "prompt": "The error handling routine checks for [[cursor]]",
    "gptLatency": 573.2381670000032,
    "llamaLatency": 366.9992080000229,
    "gptFirstTokenTime": 572.887166999979,
    "llamaFirstTokenTime": 343.9814999999944,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 206.23895899998024
  },
  {
    "prompt": "If validation fails, the form will [[cursor]]",
    "gptLatency": 570.6725420000148,
    "llamaLatency": 248.06750000000466,
    "gptFirstTokenTime": 539.511959000025,
    "llamaFirstTokenTime": 230.29254100000253,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 322.60504200001014
  },
  {
    "prompt": "The autocomplete functionality allows users to [[cursor]]",
    "gptLatency": 538.0769999999902,
    "llamaLatency": 260.4321249999921,
    "gptFirstTokenTime": 488.3742499999935,
    "llamaFirstTokenTime": 221.21675000002142,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 277.64487499999814
  },
  {
    "prompt": "The new dashboard displays [[cursor]]",
    "gptLatency": 23485.667625000002,
    "llamaLatency": 316.86087499995483,
    "gptFirstTokenTime": 23481.219666999998,
    "llamaFirstTokenTime": 233.3524159999797,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 10,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 23168.806750000047
  },
  {
    "prompt": "The search feature includes [[cursor]]",
    "gptLatency": 533.7109170000185,
    "llamaLatency": 268.08029199996963,
    "gptFirstTokenTime": 533.0239170000423,
    "llamaFirstTokenTime": 231.96495799999684,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 265.6306250000489
  },
  {
    "prompt": "The notification system alerts users when [[cursor]]",
    "gptLatency": 508.6267919999664,
    "llamaLatency": 277.76712500001304,
    "gptFirstTokenTime": 504.38758399995277,
    "llamaFirstTokenTime": 227.80866699997569,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 6,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 230.85966699995333
  },
  {
    "prompt": "The export function generates [[cursor]]",
    "gptLatency": 595.2619589999667,
    "llamaLatency": 284.2428749999963,
    "gptFirstTokenTime": 592.4845839999616,
    "llamaFirstTokenTime": 228.05179100000532,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 7,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 311.01908399997046
  },
  {
    "prompt": "The installation process requires [[cursor]]",
    "gptLatency": 728.7130829999805,
    "llamaLatency": 268.9532500000205,
    "gptFirstTokenTime": 700.1349579999805,
    "llamaFirstTokenTime": 228.00008399999933,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 459.75983299996005
  },
  {
    "prompt": "The configuration file contains [[cursor]]",
    "gptLatency": 576.1717910000007,
    "llamaLatency": 252.40687499998603,
    "gptFirstTokenTime": 575.8269580000197,
    "llamaFirstTokenTime": 228.35612499999115,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 323.76491600001464
  },
  {
    "prompt": "The API documentation describes [[cursor]]",
    "gptLatency": 560.039999999979,
    "llamaLatency": 284.5102080000215,
    "gptFirstTokenTime": 491.202042000019,
    "llamaFirstTokenTime": 225.9136249999865,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 7,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 275.5297919999575
  },
  {
    "prompt": "The user guide explains how to [[cursor]]",
    "gptLatency": 577.6589579999563,
    "llamaLatency": 266.10566599998856,
    "gptFirstTokenTime": 577.31341599999,
    "llamaFirstTokenTime": 233.62691599997925,
    "gptTotalTokens": 1,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 311.55329199996777
  },
  {
    "prompt": "The troubleshooting section covers [[cursor]]",
    "gptLatency": 604.7966250000172,
    "llamaLatency": 280.97925000003306,
    "gptFirstTokenTime": 586.2025420000427,
    "llamaFirstTokenTime": 233.70795900002122,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 6,
    "timestamp": "2024-12-03T12:48:09.302Z",
    "difference": 323.81737499998417
  }
]