[
  {
    "prompt": "The old house creaked in the wind, its windows [[cursor]]",
    "gptLatency": 819.6830829999999,
    "llamaLatency": 224.48550000000023,
    "gptFirstTokenTime": 802.5519159999999,
    "llamaFirstTokenTime": 192.7130420000001,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 595.1975829999997
  },
  {
    "prompt": "She opened the mysterious package and found [[cursor]]",
    "gptLatency": 681.3375000000005,
    "llamaLatency": 208.45029199999954,
    "gptFirstTokenTime": 655.1541669999997,
    "llamaFirstTokenTime": 188.11266700000033,
    "gptTotalTokens": 6,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 472.887208000001
  },
  {
    "prompt": "The storm clouds gathered overhead as the [[cursor]]",
    "gptLatency": 529.8989169999995,
    "llamaLatency": 249.5200420000001,
    "gptFirstTokenTime": 467.0154169999996,
    "llamaFirstTokenTime": 194.39450000000033,
    "gptTotalTokens": 8,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 280.3788749999994
  },
  {
    "prompt": "In the depths of the ancient forest, the [[cursor]]",
    "gptLatency": 591.9357909999999,
    "llamaLatency": 229.160167,
    "gptFirstTokenTime": 571.2677499999991,
    "llamaFirstTokenTime": 208.23341699999946,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 362.7756239999999
  },
  {
    "prompt": "The scientist's latest experiment had resulted in [[cursor]]",
    "gptLatency": 539.7648750000008,
    "llamaLatency": 222.32958399999916,
    "gptFirstTokenTime": 538.3723330000012,
    "llamaFirstTokenTime": 190.7073339999988,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 317.4352910000016
  },
  {
    "prompt": "The quarterly report showed significant growth in [[cursor]]",
    "gptLatency": 556.1772079999973,
    "llamaLatency": 209.91266600000017,
    "gptFirstTokenTime": 553.1235829999969,
    "llamaFirstTokenTime": 190.80266600000323,
    "gptTotalTokens": 6,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 346.26454199999716
  },
  {
    "prompt": "During the stakeholder meeting, we discussed [[cursor]]",
    "gptLatency": 570.4498749999984,
    "llamaLatency": 220.41041600000244,
    "gptFirstTokenTime": 465.53387499999735,
    "llamaFirstTokenTime": 188.08304100000169,
    "gptTotalTokens": 7,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 350.039458999996
  },
  {
    "prompt": "The new marketing strategy focuses on [[cursor]]",
    "gptLatency": 665.2485420000012,
    "llamaLatency": 241.08495799999946,
    "gptFirstTokenTime": 663.7216249999983,
    "llamaFirstTokenTime": 197.62779199999932,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 424.1635840000017
  },
  {
    "prompt": "Our team successfully implemented the [[cursor]]",
    "gptLatency": 543.6132499999985,
    "llamaLatency": 222.32529200000135,
    "gptFirstTokenTime": 542.4948330000007,
    "llamaFirstTokenTime": 190.80983299999934,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 321.28795799999716
  },
  {
    "prompt": "The client feedback indicated that [[cursor]]",
    "gptLatency": 588.1065420000014,
    "llamaLatency": 271.953125,
    "gptFirstTokenTime": 577.8496670000022,
    "llamaFirstTokenTime": 184.35725000000093,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 8,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 316.15341700000135
  },
  {
    "prompt": "The system architecture consists of [[cursor]]",
    "gptLatency": 503.90437500000553,
    "llamaLatency": 220.4051249999975,
    "gptFirstTokenTime": 502.49470800000563,
    "llamaFirstTokenTime": 187.98695800000132,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 283.49925000000803
  },
  {
    "prompt": "To optimize the database performance, we [[cursor]]",
    "gptLatency": 647.4110839999994,
    "llamaLatency": 292.4097499999989,
    "gptFirstTokenTime": 646.3740840000028,
    "llamaFirstTokenTime": 193.44225000000006,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 9,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 355.0013340000005
  },
  {
    "prompt": "The main function recursively calls [[cursor]]",
    "gptLatency": 640.5740829999995,
    "llamaLatency": 272.9444169999988,
    "gptFirstTokenTime": 600.1821249999994,
    "llamaFirstTokenTime": 184.9603750000024,
    "gptTotalTokens": 6,
    "llamaTotalTokens": 8,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 367.6296660000007
  },
  {
    "prompt": "The API endpoint returns [[cursor]]",
    "gptLatency": 608.5068749999991,
    "llamaLatency": 214.53008400000544,
    "gptFirstTokenTime": 607.5454170000012,
    "llamaFirstTokenTime": 181.6622920000009,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 393.9767909999937
  },
  {
    "prompt": "The deployment pipeline includes [[cursor]]",
    "gptLatency": 775.8046669999967,
    "llamaLatency": 207.06812499999796,
    "gptFirstTokenTime": 683.1796669999967,
    "llamaFirstTokenTime": 187.07004199999938,
    "gptTotalTokens": 7,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 568.7365419999987
  },
  {
    "prompt": "The research findings suggest that [[cursor]]",
    "gptLatency": 1353.3031249999985,
    "llamaLatency": 265.76991600000474,
    "gptFirstTokenTime": 1306.3186249999999,
    "llamaFirstTokenTime": 189.3675000000003,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 7,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 1087.5332089999938
  },
  {
    "prompt": "According to recent studies, the phenomenon [[cursor]]",
    "gptLatency": 621.7745409999989,
    "llamaLatency": 281.7856249999968,
    "gptFirstTokenTime": 619.3940409999996,
    "llamaFirstTokenTime": 172.11770799999795,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 10,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 339.98891600000206
  },
  {
    "prompt": "The data analysis reveals a strong correlation between [[cursor]]",
    "gptLatency": 664.6446250000008,
    "llamaLatency": 245.90274999999383,
    "gptFirstTokenTime": 631.3425419999985,
    "llamaFirstTokenTime": 180.23558399999456,
    "gptTotalTokens": 6,
    "llamaTotalTokens": 6,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 418.741875000007
  },
  {
    "prompt": "The experimental results demonstrate [[cursor]]",
    "gptLatency": 533.3212079999939,
    "llamaLatency": 251.51958300000115,
    "gptFirstTokenTime": 499.3751249999914,
    "llamaFirstTokenTime": 186.20762499999546,
    "gptTotalTokens": 6,
    "llamaTotalTokens": 6,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 281.8016249999928
  },
  {
    "prompt": "The literature review indicates [[cursor]]",
    "gptLatency": 550.6885000000038,
    "llamaLatency": 265.429707999996,
    "gptFirstTokenTime": 536.0682500000112,
    "llamaFirstTokenTime": 188.65720800000418,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 7,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 285.2587920000078
  },
  {
    "prompt": "The mountain peak disappeared into [[cursor]]",
    "gptLatency": 530.265916999997,
    "llamaLatency": 208.77870900000562,
    "gptFirstTokenTime": 529.7121669999906,
    "llamaFirstTokenTime": 177.57908399999724,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 321.48720799999137
  },
  {
    "prompt": "The child's laughter echoed through [[cursor]]",
    "gptLatency": 598.6328340000036,
    "llamaLatency": 220.66520899999887,
    "gptFirstTokenTime": 597.712875000012,
    "llamaFirstTokenTime": 189.3614169999928,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 377.9676250000048
  },
  {
    "prompt": "The art exhibition featured [[cursor]]",
    "gptLatency": 506.7877920000028,
    "llamaLatency": 229.87870800000383,
    "gptFirstTokenTime": 506.70929199999955,
    "llamaFirstTokenTime": 187.15904199999932,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 276.909083999999
  },
  {
    "prompt": "The chef carefully prepared [[cursor]]",
    "gptLatency": 639.4887500000041,
    "llamaLatency": 230.74608300000546,
    "gptFirstTokenTime": 564.1906250000029,
    "llamaFirstTokenTime": 176.58666600000288,
    "gptTotalTokens": 8,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 408.7426669999986
  },
  {
    "prompt": "The garden bloomed with [[cursor]]",
    "gptLatency": 608.4225000000006,
    "llamaLatency": 240.04787500000384,
    "gptFirstTokenTime": 607.5877920000057,
    "llamaFirstTokenTime": 197.02779200000805,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 368.37462499999674
  },
  {
    "prompt": "As the sun set behind the hills, she [[cursor]]",
    "gptLatency": 520.1919999999955,
    "llamaLatency": 282.60683300001256,
    "gptFirstTokenTime": 505.9743749999907,
    "llamaFirstTokenTime": 183.51737500001036,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 9,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 237.5851669999829
  },
  {
    "prompt": "The detective examined the evidence and [[cursor]]",
    "gptLatency": 730.6286249999976,
    "llamaLatency": 268.919332999998,
    "gptFirstTokenTime": 729.349457999997,
    "llamaFirstTokenTime": 189.91316599999845,
    "gptTotalTokens": 6,
    "llamaTotalTokens": 8,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 461.70929199999955
  },
  {
    "prompt": "After reviewing the documents, he realized [[cursor]]",
    "gptLatency": 566.182249999998,
    "llamaLatency": 263.4138329999987,
    "gptFirstTokenTime": 513.700417,
    "llamaFirstTokenTime": 186.95454200000677,
    "gptTotalTokens": 7,
    "llamaTotalTokens": 7,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 302.7684169999993
  },
  {
    "prompt": "The spacecraft's sensors detected [[cursor]]",
    "gptLatency": 572.1389579999959,
    "llamaLatency": 272.97750000000815,
    "gptFirstTokenTime": 571.0905829999974,
    "llamaFirstTokenTime": 185.1180000000022,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 8,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 299.16145799998776
  },
  {
    "prompt": "Walking through the abandoned building, they [[cursor]]",
    "gptLatency": 633.1650420000078,
    "llamaLatency": 270.5974169999972,
    "gptFirstTokenTime": 553.0725000000093,
    "llamaFirstTokenTime": 182.0049169999984,
    "gptTotalTokens": 7,
    "llamaTotalTokens": 8,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 362.5676250000106
  },
  {
    "prompt": "I am writing to follow up on our discussion regarding [[cursor]]",
    "gptLatency": 1163.283792000002,
    "llamaLatency": 178.45516599999974,
    "gptFirstTokenTime": 1131.9495829999942,
    "llamaFirstTokenTime": 149.1502909999981,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 984.8286260000023
  },
  {
    "prompt": "Thank you for your inquiry about [[cursor]]",
    "gptLatency": 586.7044160000078,
    "llamaLatency": 213.81575000000885,
    "gptFirstTokenTime": 586.1316250000091,
    "llamaFirstTokenTime": 181.1218749999971,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 372.8886659999989
  },
  {
    "prompt": "I would like to schedule a meeting to discuss [[cursor]]",
    "gptLatency": 605.9191250000003,
    "llamaLatency": 226.13179200000013,
    "gptFirstTokenTime": 604.775833000007,
    "llamaFirstTokenTime": 183.02808399999049,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 379.7873330000002
  },
  {
    "prompt": "Please find attached the documentation for [[cursor]]",
    "gptLatency": 689.8761669999949,
    "llamaLatency": 219.6459169999871,
    "gptFirstTokenTime": 689.0771669999958,
    "llamaFirstTokenTime": 177.89295799999672,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 470.2302500000078
  },
  {
    "prompt": "In response to your request for [[cursor]]",
    "gptLatency": 714.7109590000182,
    "llamaLatency": 156.37595799998962,
    "gptFirstTokenTime": 667.3029170000227,
    "llamaFirstTokenTime": 147.03966700000456,
    "gptTotalTokens": 10,
    "llamaTotalTokens": 1,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 558.3350010000286
  },
  {
    "prompt": "The new feature implementation will require [[cursor]]",
    "gptLatency": 543.6554170000018,
    "llamaLatency": 239.76712500001304,
    "gptFirstTokenTime": 485.82850000000326,
    "llamaFirstTokenTime": 185.19974999999977,
    "gptTotalTokens": 6,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 303.8882919999887
  },
  {
    "prompt": "The testing phase revealed several [[cursor]]",
    "gptLatency": 561.6429580000113,
    "llamaLatency": 249.4415839999856,
    "gptFirstTokenTime": 561.4305000000168,
    "llamaFirstTokenTime": 194.79062499999418,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 312.2013740000257
  },
  {
    "prompt": "User feedback indicates that the interface [[cursor]]",
    "gptLatency": 656.6145419999957,
    "llamaLatency": 248.55849999998463,
    "gptFirstTokenTime": 656.0024999999732,
    "llamaFirstTokenTime": 193.9287909999839,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 408.0560420000111
  },
  {
    "prompt": "The security audit identified [[cursor]]",
    "gptLatency": 611.6710420000018,
    "llamaLatency": 235.92470800000592,
    "gptFirstTokenTime": 603.2479170000006,
    "llamaFirstTokenTime": 195.2558330000029,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 375.74633399999584
  },
  {
    "prompt": "The performance metrics show [[cursor]]",
    "gptLatency": 577.3240410000144,
    "llamaLatency": 250.7855419999978,
    "gptFirstTokenTime": 575.8153750000056,
    "llamaFirstTokenTime": 185.1610000000219,
    "gptTotalTokens": 8,
    "llamaTotalTokens": 6,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 326.5384990000166
  },
  {
    "prompt": "The cat quietly [[cursor]]",
    "gptLatency": 870.7421669999894,
    "llamaLatency": 236.22349999999278,
    "gptFirstTokenTime": 826.9174999999814,
    "llamaFirstTokenTime": 180.7799159999995,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 634.5186669999966
  },
  {
    "prompt": "She quickly [[cursor]]",
    "gptLatency": 644.7896249999758,
    "llamaLatency": 308.3495410000032,
    "gptFirstTokenTime": 506.34375,
    "llamaFirstTokenTime": 186.677915999986,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 11,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 336.44008399997256
  },
  {
    "prompt": "The software automatically [[cursor]]",
    "gptLatency": 654.922041999991,
    "llamaLatency": 188.87899999998626,
    "gptFirstTokenTime": 653.7222919999913,
    "llamaFirstTokenTime": 178.87287500000093,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 1,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 466.0430420000048
  },
  {
    "prompt": "The machine learning model [[cursor]]",
    "gptLatency": 484.0412500000093,
    "llamaLatency": 234.8416660000221,
    "gptFirstTokenTime": 478.8102080000099,
    "llamaFirstTokenTime": 180.60787500001607,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 249.19958399998723
  },
  {
    "prompt": "The database query [[cursor]]",
    "gptLatency": 605.5461670000223,
    "llamaLatency": 222.21770799998194,
    "gptFirstTokenTime": 580.0487080000166,
    "llamaFirstTokenTime": 190.65325000000303,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 383.3284590000403
  },
  {
    "prompt": "Despite the challenges faced during development, the team [[cursor]]",
    "gptLatency": 529.4803339999926,
    "llamaLatency": 275.4953749999986,
    "gptFirstTokenTime": 494.6698749999923,
    "llamaFirstTokenTime": 187.10029100000975,
    "gptTotalTokens": 6,
    "llamaTotalTokens": 8,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 253.98495899999398
  },
  {
    "prompt": "While analyzing the performance metrics, we discovered [[cursor]]",
    "gptLatency": 598.9242500000109,
    "llamaLatency": 283.5574579999957,
    "gptFirstTokenTime": 597.6786670000001,
    "llamaFirstTokenTime": 183.13949999999022,
    "gptTotalTokens": 7,
    "llamaTotalTokens": 9,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 315.36679200001527
  },
  {
    "prompt": "Although initial results were promising, further testing [[cursor]]",
    "gptLatency": 704.7259999999951,
    "llamaLatency": 255.09895899999538,
    "gptFirstTokenTime": 702.3318750000035,
    "llamaFirstTokenTime": 189.24862500000745,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 6,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 449.62704099999974
  },
  {
    "prompt": "Considering the project requirements, we decided to [[cursor]]",
    "gptLatency": 563.9816249999858,
    "llamaLatency": 257.14420800001244,
    "gptFirstTokenTime": 496.6386249999923,
    "llamaFirstTokenTime": 191.47816600001534,
    "gptTotalTokens": 6,
    "llamaTotalTokens": 6,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 306.83741699997336
  },
  {
    "prompt": "After implementing the new algorithm, the system [[cursor]]",
    "gptLatency": 595.6069579999894,
    "llamaLatency": 236.22075000000768,
    "gptFirstTokenTime": 594.8530829999945,
    "llamaFirstTokenTime": 193.44033400001354,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 359.3862079999817
  },
  {
    "prompt": "\"I never expected to find,\" she whispered [[cursor]]",
    "gptLatency": 649.7855829999899,
    "llamaLatency": 205.95283299998846,
    "gptFirstTokenTime": 648.4819159999897,
    "llamaFirstTokenTime": 184.79579099998227,
    "gptTotalTokens": 6,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 443.8327500000014
  },
  {
    "prompt": "\"The results are fascinating,\" the researcher noted [[cursor]]",
    "gptLatency": 633.2890409999818,
    "llamaLatency": 225.9325410000165,
    "gptFirstTokenTime": 631.6536659999983,
    "llamaFirstTokenTime": 182.3600410000072,
    "gptTotalTokens": 6,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 407.3564999999653
  },
  {
    "prompt": "\"According to our analysis,\" the expert explained [[cursor]]",
    "gptLatency": 706.8448330000101,
    "llamaLatency": 207.0897920000134,
    "gptFirstTokenTime": 704.8475829999952,
    "llamaFirstTokenTime": 186.67379200001596,
    "gptTotalTokens": 12,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 499.7550409999967
  },
  {
    "prompt": "\"We need to consider,\" the manager suggested [[cursor]]",
    "gptLatency": 665.9524579999852,
    "llamaLatency": 200.99445800000103,
    "gptFirstTokenTime": 542.8599159999867,
    "llamaFirstTokenTime": 180.0117920000048,
    "gptTotalTokens": 11,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 464.95799999998417
  },
  {
    "prompt": "\"The solution involves,\" the engineer stated [[cursor]]",
    "gptLatency": 752.9539999999979,
    "llamaLatency": 261.36020799999824,
    "gptFirstTokenTime": 548.2077089999802,
    "llamaFirstTokenTime": 184.68050000001676,
    "gptTotalTokens": 11,
    "llamaTotalTokens": 7,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 491.59379199999967
  },
  {
    "prompt": "The program executes the following steps: [[cursor]]",
    "gptLatency": 541.6849999999977,
    "llamaLatency": 214.4118750000198,
    "gptFirstTokenTime": 511.7303340000217,
    "llamaFirstTokenTime": 193.53383300002315,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 327.2731249999779
  },
  {
    "prompt": "The automated process begins by [[cursor]]",
    "gptLatency": 703.385540999996,
    "llamaLatency": 234.38537500001257,
    "gptFirstTokenTime": 702.1257080000069,
    "llamaFirstTokenTime": 179.57904099998996,
    "gptTotalTokens": 7,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 469.00016599998344
  },
  {
    "prompt": "The user interface responds by [[cursor]]",
    "gptLatency": 548.117957999988,
    "llamaLatency": 230.8424159999995,
    "gptFirstTokenTime": 525.3556249999965,
    "llamaFirstTokenTime": 176.84920799999963,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 317.2755419999885
  },
  {
    "prompt": "The system automatically [[cursor]]",
    "gptLatency": 8624.451583000016,
    "llamaLatency": 218.45237499999348,
    "gptFirstTokenTime": 8623.67283299999,
    "llamaFirstTokenTime": 186.3473750000121,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 8405.999208000023
  },
  {
    "prompt": "The algorithm processes the data by [[cursor]]",
    "gptLatency": 612.0323750000098,
    "llamaLatency": 235.8972079999803,
    "gptFirstTokenTime": 568.5045840000093,
    "llamaFirstTokenTime": 181.72912499998347,
    "gptTotalTokens": 7,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 376.13516700002947
  },
  {
    "prompt": "The new version must be able to [[cursor]]",
    "gptLatency": 624.0916250000009,
    "llamaLatency": 261.4371669999964,
    "gptFirstTokenTime": 623.0497920000053,
    "llamaFirstTokenTime": 207.1148749999993,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 362.6544580000045
  },
  {
    "prompt": "The application should handle [[cursor]]",
    "gptLatency": 517.5360830000136,
    "llamaLatency": 174.5966250000056,
    "gptFirstTokenTime": 509.67512500000885,
    "llamaFirstTokenTime": 154.6878330000036,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 342.939458000008
  },
  {
    "prompt": "Users need to be able to [[cursor]]",
    "gptLatency": 575.0410409999895,
    "llamaLatency": 253.09670899997582,
    "gptFirstTokenTime": 535.45404099999,
    "llamaFirstTokenTime": 188.33816699997988,
    "gptTotalTokens": 6,
    "llamaTotalTokens": 6,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 321.9443320000137
  },
  {
    "prompt": "The system must automatically [[cursor]]",
    "gptLatency": 488.6211659999972,
    "llamaLatency": 224.14641700001084,
    "gptFirstTokenTime": 487.96804099998553,
    "llamaFirstTokenTime": 192.15158400000655,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 264.47474899998633
  },
  {
    "prompt": "The interface should provide [[cursor]]",
    "gptLatency": 576.5842080000148,
    "llamaLatency": 216.31966600002488,
    "gptFirstTokenTime": 575.9364160000114,
    "llamaFirstTokenTime": 184.5008749999979,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 360.2645419999899
  },
  {
    "prompt": "If the connection fails, the system will [[cursor]]",
    "gptLatency": 756.7426670000132,
    "llamaLatency": 210.2133750000212,
    "gptFirstTokenTime": 745.1517500000191,
    "llamaFirstTokenTime": 159.38200000001234,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 546.529291999992
  },
  {
    "prompt": "When an error occurs, the application should [[cursor]]",
    "gptLatency": 491.6477910000249,
    "llamaLatency": 238.64666700002272,
    "gptFirstTokenTime": 490.58079099998577,
    "llamaFirstTokenTime": 195.41929200000595,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 253.00112400000216
  },
  {
    "prompt": "In case of data corruption, the backup [[cursor]]",
    "gptLatency": 502.3286669999943,
    "llamaLatency": 237.09895899996627,
    "gptFirstTokenTime": 497.02020800003083,
    "llamaFirstTokenTime": 182.51641699997708,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 265.22970800002804
  },
  {
    "prompt": "The error handling routine checks for [[cursor]]",
    "gptLatency": 553.9637909999583,
    "llamaLatency": 226.87770900002215,
    "gptFirstTokenTime": 553.3399159999681,
    "llamaFirstTokenTime": 194.62970900000073,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 327.08608199993614
  },
  {
    "prompt": "If validation fails, the form will [[cursor]]",
    "gptLatency": 657.7426669999841,
    "llamaLatency": 270.2364589999779,
    "gptFirstTokenTime": 656.92758399999,
    "llamaFirstTokenTime": 181.79100000002654,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 8,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 387.50620800000615
  },
  {
    "prompt": "The autocomplete functionality allows users to [[cursor]]",
    "gptLatency": 616.1099170000525,
    "llamaLatency": 248.27425000001676,
    "gptFirstTokenTime": 614.8136250000098,
    "llamaFirstTokenTime": 182.36958300002152,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 6,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 367.83566700003576
  },
  {
    "prompt": "The new dashboard displays [[cursor]]",
    "gptLatency": 541.7965829999885,
    "llamaLatency": 226.8120840000338,
    "gptFirstTokenTime": 518.1751669999794,
    "llamaFirstTokenTime": 183.29429200000595,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 314.98449899995467
  },
  {
    "prompt": "The search feature includes [[cursor]]",
    "gptLatency": 653.119000000006,
    "llamaLatency": 225.78804100002162,
    "gptFirstTokenTime": 652.4541250000475,
    "llamaFirstTokenTime": 182.82862500002375,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 427.33095899998443
  },
  {
    "prompt": "The notification system alerts users when [[cursor]]",
    "gptLatency": 24523.790792000014,
    "llamaLatency": 236.24254099995596,
    "gptFirstTokenTime": 24507.966833999963,
    "llamaFirstTokenTime": 181.66375000000698,
    "gptTotalTokens": 4,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 24287.54825100006
  },
  {
    "prompt": "The export function generates [[cursor]]",
    "gptLatency": 545.2966669999878,
    "llamaLatency": 205.69158300000709,
    "gptFirstTokenTime": 544.6048339999979,
    "llamaFirstTokenTime": 186.0498329999973,
    "gptTotalTokens": 3,
    "llamaTotalTokens": 2,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 339.6050839999807
  },
  {
    "prompt": "The installation process requires [[cursor]]",
    "gptLatency": 538.0134170000092,
    "llamaLatency": 206.20320799999172,
    "gptFirstTokenTime": 519.2822500000475,
    "llamaFirstTokenTime": 174.27262500004144,
    "gptTotalTokens": 6,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 331.8102090000175
  },
  {
    "prompt": "The configuration file contains [[cursor]]",
    "gptLatency": 465.2924580000108,
    "llamaLatency": 206.16204100003233,
    "gptFirstTokenTime": 464.97608300001593,
    "llamaFirstTokenTime": 156.56037500000093,
    "gptTotalTokens": 2,
    "llamaTotalTokens": 5,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 259.1304169999785
  },
  {
    "prompt": "The API documentation describes [[cursor]]",
    "gptLatency": 2909.374959000037,
    "llamaLatency": 262.6006669999915,
    "gptFirstTokenTime": 2900.111499999999,
    "llamaFirstTokenTime": 186.0288329999894,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 7,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 2646.7742920000455
  },
  {
    "prompt": "The user guide explains how to [[cursor]]",
    "gptLatency": 699.2179170000018,
    "llamaLatency": 214.09179199999198,
    "gptFirstTokenTime": 698.4765839999891,
    "llamaFirstTokenTime": 182.1593329999596,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 3,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 485.1261250000098
  },
  {
    "prompt": "The troubleshooting section covers [[cursor]]",
    "gptLatency": 771.6214170000167,
    "llamaLatency": 229.31983399996534,
    "gptFirstTokenTime": 770.4197500000009,
    "llamaFirstTokenTime": 186.61858399998164,
    "gptTotalTokens": 5,
    "llamaTotalTokens": 4,
    "timestamp": "2024-12-02T18:15:46.592Z",
    "difference": 542.3015830000513
  }
]